{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport h5py # Read and write HDF5 files from Python\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/ei-dreem-sleep-stages-2020/y_train.csv\n/kaggle/input/ei-dreem-sleep-stages-2020/X_train.h5\n/kaggle/input/ei-dreem-sleep-stages-2020/X_test.h5\n/kaggle/input/ei-dreem-sleep-stages-2020/sample_submission.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Now we are going into the Dreem 2 Challenge.\nThe goal is to use Dreem 2 headband data to perform sleep stage scoring on 30 seconds epochs of biophysiological signals.\nhttps://www.kaggle.com/c/ei-dreem-sleep-stages-2020/data\n\nThe training dataset is composed of:\n- X_train.h5: input Dreem2 headband data: 30s of biosignals including EEG and accelerometer\n- y_train: sleep stages {'Wake':0, 'N1':1, 'N2':2, 'N3':3, 'REM':4} \n\nThe challenge is to submit the sleep stages associated to:\n- X_test.h5\n(it has to be submitted in the right format, see sample_submission.csv)\n\nLet's have a look:\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# filenames\ndata_path = \"/kaggle/input/ei-dreem-sleep-stages-2020/\"\nfile_xtrain = data_path + \"X_train.h5\"\nfile_xtest = data_path + \"X_test.h5\"\nfile_ytrain = data_path + \"y_train.csv\"\n\n#","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this TD, we will only work with one EEG channel.\nLet's create dataset functions that will be used for training and testing the model:\n\n*EegEpochDataset*: Eeg Class herited from pytorch Dataset to deal with our data\n\n*get_train_validation_dataset*: \n- return train_dataloader and validation_dataloader\n- dataloaders will be used during the training and the tests\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\"\"\" Load project data\n    DataLoader and Dataset for single-channel EEG\n\n\"\"\"\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n\ndef normalize_data(eeg_array):\n    \"\"\"normalize signal between 0 and 1\"\"\"\n\n    normalized_array = np.clip(eeg_array, -150, 150)\n    normalized_array = normalized_array / 150\n\n    return normalized_array\n\n\nclass EegEpochDataset(Dataset):\n    \"\"\"EEG Epochs dataset.\"\"\"\n\n    def __init__(self, x_data, y_data, transform=None):\n        \"\"\"\n        Args:\n            x_data (numpy array): Numpy array of input data.\n            y_data (list of numpy array): Sleep Stages\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.y_data = y_data\n        self.x_data = x_data\n        self.transform = transform\n\n        self.x_data = normalize_data(x_data)\n\n    def __len__(self):\n        return len(self.y_data)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        signal = np.expand_dims(self.x_data[idx], axis=0)\n        stage = self.y_data[idx]\n\n        if self.transform:\n            signal = self.transform(signal)\n\n        return signal, stage\n\n\ndef get_train_validation_dataset(derivation, batch_size=32, validation_ratio=0.2):\n    \"\"\"\n    Return train and validation datasets in Dataloader format\n    :param derivation: EEG derivation, from eeg_1 to eeg_7\n    :param batch_size: size of the batch, usually 16, 3Ã© or 64\n    :param validation_ratio:\n\n    :return:\n    train_dataloader\n    validation_dataloader\n    \"\"\"\n\n    with h5py.File(file_xtrain, \"r\") as fi:\n        x_data = fi[derivation][()]\n    y_data = pd.read_csv(file_ytrain)['sleep_stage'].to_numpy()\n\n    # Creating data indices for training and validation splits:\n    dataset_size = len(y_data)\n    indices = list(range(dataset_size))\n    split = int((1 - validation_ratio) * dataset_size)\n    np.random.shuffle(indices)\n    train_indices, val_indices = indices[:split], indices[split:]\n\n    x_train, x_validation = x_data[train_indices], x_data[val_indices]\n    y_train, y_validation = y_data[train_indices], y_data[val_indices]\n\n    # torch dataset\n    train_dataset = EegEpochDataset(x_data=x_train, y_data=y_train)\n    val_dataset = EegEpochDataset(x_data=x_validation, y_data=y_validation)\n\n    # to dataloader\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n\n    return train_dataloader, val_dataloader\n\n\n# load dataloaders\ntrain_dataloader, validation_dataloader = get_train_validation_dataset('eeg_5', batch_size=32)\n","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we create the neural network Model:\n- convolutionnal neural network\n- Fully conencted layers at the end\n- takes only a single channel of EEG signal as input"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass SingleChannelConvNet(nn.Module):\n\n    def __init__(self):\n        super(SingleChannelConvNet, self).__init__()\n        self.conv_a = nn.Conv1d(1, 128, 7, stride=2, padding=6, padding_mode='zeros')\n        self.conv_b = nn.Conv1d(128, 128, 7, stride=2, padding=6, padding_mode='zeros')\n        self.conv_c = nn.Conv1d(128, 256, 7, stride=2, padding=6, padding_mode='zeros')\n        self.conv_d = nn.Conv1d(256, 256, 5, stride=2, padding=4, padding_mode='zeros')\n        self.conv_e = nn.Conv1d(256, 256, 3, stride=2, padding=2, padding_mode='zeros')\n\n        self.pool = nn.MaxPool1d(2)\n\n        self.activfunc_a = nn.LeakyReLU(negative_slope=0.1)\n\n        self.fc1 = nn.Linear(3 * 256, 100)\n        self.fc2 = nn.Linear(100, 5)\n\n    def forward(self, x):\n\n        x = self.activfunc_a(self.conv_a(x))\n        for _ in range(5):\n            x = self.activfunc_a(self.conv_b(x))\n        x = self.activfunc_a(self.conv_c(x))\n        for _ in range(3):\n            x = self.activfunc_a(self.conv_d(x))\n        x = self.activfunc_a(self.conv_e(x))\n        x = self.activfunc_a(self.conv_e(x))\n\n        x = x.view(-1, self.num_flat_features(x))\n        x = self.activfunc_a(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can now start the training on the train dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# device: use GPU if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# parameters\nlearning_rate = 0.001\nn_epoch = 50\n\n# neural network and co\nmy_net = SingleChannelConvNet()\nmy_net = my_net.to(device) # model into GPU\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(my_net.parameters(), lr=learning_rate)\n\nprint('training...')\nfor epoch in range(n_epoch):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(train_dataloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = my_net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n    print('epoch %d, %d samples, loss: %.3f' % (epoch + 1, (i+1)*train_dataloader.batch_size,running_loss / (i+1)))\n    running_loss = 0.0\n\nprint('Finished Training')\n","execution_count":9,"outputs":[{"output_type":"stream","text":"training...\nepoch 1, 19776 samples, loss: 1.461\nepoch 2, 19776 samples, loss: 1244.654\nepoch 3, 19776 samples, loss: 3.593\nepoch 4, 19776 samples, loss: 1.467\nepoch 5, 19776 samples, loss: 1.444\nepoch 6, 19776 samples, loss: 1.428\nepoch 7, 19776 samples, loss: 1.411\nepoch 8, 19776 samples, loss: 1.387\nepoch 9, 19776 samples, loss: 1.453\nepoch 10, 19776 samples, loss: 1.373\nepoch 11, 19776 samples, loss: 1.345\nepoch 12, 19776 samples, loss: 1.431\nepoch 13, 19776 samples, loss: 2.177\nepoch 14, 19776 samples, loss: 1.334\nepoch 15, 19776 samples, loss: 1.300\nepoch 16, 19776 samples, loss: 1.267\nepoch 17, 19776 samples, loss: 1.253\nepoch 18, 19776 samples, loss: 68.422\nepoch 19, 19776 samples, loss: 1.246\nepoch 20, 19776 samples, loss: 1.213\nepoch 21, 19776 samples, loss: 1.194\nepoch 22, 19776 samples, loss: 1.173\nepoch 23, 19776 samples, loss: 1.165\nepoch 24, 19776 samples, loss: 1.151\nepoch 25, 19776 samples, loss: 1.150\nepoch 26, 19776 samples, loss: 1.160\nepoch 27, 19776 samples, loss: 1.137\nepoch 28, 19776 samples, loss: 1.126\nepoch 29, 19776 samples, loss: 1.117\nepoch 30, 19776 samples, loss: 1.116\nepoch 31, 19776 samples, loss: 1.103\nepoch 32, 19776 samples, loss: 1.096\nepoch 33, 19776 samples, loss: 1.081\nepoch 34, 19776 samples, loss: 1.051\nepoch 35, 19776 samples, loss: 1.027\nepoch 36, 19776 samples, loss: 0.995\nepoch 37, 19776 samples, loss: 0.983\nepoch 38, 19776 samples, loss: 0.967\nepoch 39, 19776 samples, loss: 0.945\nepoch 40, 19776 samples, loss: 0.925\nepoch 41, 19776 samples, loss: 0.908\nepoch 42, 19776 samples, loss: 0.888\nepoch 43, 19776 samples, loss: 0.883\nepoch 44, 19776 samples, loss: 0.904\nepoch 45, 19776 samples, loss: 0.848\nepoch 46, 19776 samples, loss: 0.822\nepoch 47, 19776 samples, loss: 0.803\nepoch 48, 19776 samples, loss: 0.776\nepoch 49, 19776 samples, loss: 0.758\nepoch 50, 19776 samples, loss: 0.738\nFinished Training\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Now the training is complete, let's assess its performance on the validation data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, confusion_matrix\n\n# params\nclasses = ['Wake', 'N1', 'N2', 'N3', 'REM']\n\nwith torch.no_grad():\n    prediction_list = torch.empty(0).to(device)\n    true_list = torch.empty(0).to(device)\n    for data in validation_dataloader:\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        outputs = my_net(inputs)\n        _, predicted = torch.max(outputs, 1)\n        prediction_list = torch.cat([prediction_list, predicted])\n        true_list = torch.cat([true_list, labels])\n\ntrue_list = true_list.cpu().numpy()\nprediction_list = prediction_list.cpu().numpy()\nscores = {'balanced_accuracy': balanced_accuracy_score(true_list, prediction_list),\n            'cohen_kappa_score': cohen_kappa_score(true_list, prediction_list),\n            'confusion_matrix': confusion_matrix(true_list, prediction_list)}\n\nprint(scores)","execution_count":10,"outputs":[{"output_type":"stream","text":"{'balanced_accuracy': 0.5710283075038346, 'cohen_kappa_score': 0.5631847206015818, 'confusion_matrix': array([[ 406,    5,  108,   27,  162],\n       [  21,    4,  151,   17,  144],\n       [  23,    1, 1392,  223,  197],\n       [   5,    0,  116,  943,    0],\n       [  24,    2,  329,   17,  621]])}\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}