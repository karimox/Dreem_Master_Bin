{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_Sleep_Staging_B.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25mYtkZbNgnq"
      },
      "source": [
        "Launch the following blocks to connect to your drive and go into the tutorial folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpSZkaqFDrRN"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pokgRnDVDxzZ"
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/TD_Dreem_MasterBin/Dreem_Master_Bin\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br682vIyDkCy"
      },
      "source": [
        "This tutorial is about machine learning methods for sleep stage classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZONWWYI-hKl6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dreem_master_bin.hypnogram import plot_hypnogram, stage_colors"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnHoNfP4hLUl"
      },
      "source": [
        "To save you some time, train and test datasets are and are available in the data folder. It consists of preprocessed data, not raw record. You have two types of datasets:\n",
        "\n",
        "- Spectral dataset = data containing spectral power (spectrogram matrix): train and test\n",
        "- Features dataset = data containing precomputed features: train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfzUJqPPboAi"
      },
      "source": [
        "from dreem_master_bin.load_data import load_spectral_datasets, load_feature_datasets\n",
        "\n",
        "# load spectrogram dataset and shuffle train data\n",
        "x_train_spect, y_train_spect, x_test_spect, y_test_spect = load_spectral_datasets()\n",
        "spectral_names = ['index_window', '1Hz', '2Hz', '3Hz', '4Hz', '5Hz', '6Hz', '7Hz',\n",
        "                  '8Hz', '9Hz', '10Hz', '11Hz', '12Hz', '13Hz', '14Hz', '15Hz', \n",
        "                  '16Hz', '18Hz', '19Hz']\n",
        "# shuffle train dataset\n",
        "p = np.random.permutation(len(y_train_spect))\n",
        "x_train_spect, y_train_spect = x_train_spect[p], y_train_spect[p]\n",
        "\n",
        "\n",
        "# load precomputed features dataset and shuffle train data\n",
        "x_train_feat, y_train_feat, x_test_feat, y_test_feat = load_feature_datasets()\n",
        "features_name = ['index_window', 'delta', 'delta_r', 'theta', 'theta_r',\n",
        "       'lowfreq', 'lowfreq_r', 'alpha', 'alpha_r', 'sigma', 'sigma_r', 'beta',\n",
        "       'beta_r', 'kcomp', 'kcomp_r', 'SC', 'SEF90', 'SEF95', 'Nb spindles',\n",
        "       'spindles magnitude', 'spindles duration', 'Nb slow waves',\n",
        "       'slow waves magnitude', 'slow waves duration', 'AccelerometerVar',\n",
        "       'little movement', 'strong movement']\n",
        "# shuffle train dataset\n",
        "p = np.random.permutation(len(y_train_feat))\n",
        "x_train_feat, y_train_feat = x_train_feat[p], y_train_feat[p]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMXTLgSVb-Vk"
      },
      "source": [
        "We have just loaded the spectral data:\n",
        "\n",
        "- x_train_spect, x_test_spect: spectral data to predict sleep stages\n",
        "It is an array of shape n_samples x n_features\n",
        "\n",
        "    - n_samples = number of sleep epochs\n",
        "    - n_features = number of features for each of these epochs. The features are: [index_window, power_frequency_1Hz, power_frequency_2Hz, ..., power_frequency_18Hz], where index window to the position of the sample in its sleep record.\n",
        "- y_train_spect, y_test_spect: labels (sleep stages)\n",
        "\n",
        "Then, we have loaded the other dataset:\n",
        "\n",
        "- x_train_spect, x_test_spect: shape n_samples x n_features\n",
        "    - n_features = the features are ['index_window', 'delta', 'delta_r', 'theta', 'theta_r', 'lowfreq', 'lowfreq_r', 'alpha', 'alpha_r', 'sigma', 'sigma_r', 'beta', 'beta_r', 'kcomp', 'kcomp_r', 'SC', 'SEF90', 'SEF95', 'Nb spindles', 'spindles magnitude', 'spindles duration', 'Nb slow waves', 'slow waves magnitude', 'slow waves duration', 'AccelerometerVar','little movement', 'strong movement']\n",
        "\n",
        "- y_train_spect, y_test_spect: labels (sleep stages)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68gD5UbGEDod"
      },
      "source": [
        "Let's start with the spectral dataset !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZcvEkUvDjWX"
      },
      "source": [
        "x_train, y_train = x_train_spect, y_train_spect\n",
        "x_test, y_test = x_test_spect, y_test_spect"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv-Rft5PEcHk"
      },
      "source": [
        "1 - Dimension reduction + (linear) classifier\n",
        "\n",
        "- Choose an algorithm for dimension reduction (e.g PCA)\n",
        "- Choose a (linear) classifier (e.g SVM classifier)\n",
        "\n",
        "\n",
        "You can go to the online documentation of the scikit-library to find similar functions, with the keywords: \n",
        "- multi class classifier\n",
        "- dimension reduction\n",
        "- decomposition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekji3UiPEO5_"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# scale input data and reduce dimension\n",
        "pca = make_pipeline(StandardScaler(),\n",
        "                    PCA(n_components=5, random_state=10))\n",
        "pca.fit(x_train, y_train)\n",
        "\n",
        "# linear classifier\n",
        "classifier = SVC(kernel='linear')\n",
        "# training: fit the model to the data\n",
        "classifier.fit(pca.transform(x_train), y_train)\n",
        "\n",
        "# test it\n",
        "predictions = classifier.predict(pca.transform(x_test))\n",
        "scores = {'balanced_accuracy': balanced_accuracy_score(y_test, predictions),\n",
        "            'cohen_kappa': cohen_kappa_score(y_test, predictions),\n",
        "            'confusion_matrix': confusion_matrix(y_test, predictions)}\n",
        "\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7---cUpLE-lN"
      },
      "source": [
        "2 - Ensemble learning\n",
        "https://scikit-learn.org/stable/modules/ensemble.html\n",
        "\n",
        "Here we are going to use the Random Forest method, try to use other ensemble learning functions of the scikit-learn library.\n",
        "Also we are going to work with preprocessed features.\n",
        "\n",
        "Go to the online documentation of these functions to set the parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp7B5w_GHhYH"
      },
      "source": [
        "# load features dataset and shuffle train data\n",
        "x_train, y_train = x_train_feat, y_train_feat\n",
        "x_test, y_test = x_test_feat, y_test_feat\n",
        "\n",
        "# select a classifier and train it\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf_rf = make_pipeline(StandardScaler(),\n",
        "                       RandomForestClassifier(max_depth=10, random_state=42))\n",
        "print('training...')\n",
        "clf_rf.fit(x_train, y_train)\n",
        "\n",
        "# test it\n",
        "predictions = clf_rf.predict(x_test)\n",
        "scores = {'balanced_accuracy': balanced_accuracy_score(y_test, predictions),\n",
        "            'cohen_kappa_score': cohen_kappa_score(y_test, predictions),\n",
        "            'confusion_matrix': confusion_matrix(y_test, predictions)}\n",
        "\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0nHioKyTpdz"
      },
      "source": [
        "3 - Stack multiple estimators\n",
        "\n",
        "It is possible to combine multiple machine learning algorithms to improve performance.\n",
        "\n",
        "> Use the StackingClassifier to stack estimators with a final classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxRGV5fRTvx5"
      },
      "source": [
        "# select a classifier and train it\n",
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "rf_pipeline = make_pipeline(StandardScaler(),\n",
        "                            RandomForestClassifier(n_estimators=10, random_state=42))\n",
        "gradient_pipeline = make_pipeline(StandardScaler(),\n",
        "                                  HistGradientBoostingClassifier(learning_rate=0.01, random_state=30))\n",
        "estimators = [('Random Forest', rf_pipeline),\n",
        "                  ('Gradient Boosting', gradient_pipeline)]\n",
        "stacking_classifier = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=200))\n",
        "\n",
        "print('training...')\n",
        "stacking_classifier.fit(x_train, y_train)\n",
        "\n",
        "# test it\n",
        "predictions = stacking_classifier.predict(x_test)\n",
        "scores = {'balanced_accuracy': balanced_accuracy_score(y_test, predictions),\n",
        "          'cohen_kappa_score': cohen_kappa_score(y_test, predictions),\n",
        "          'confusion_matrix': confusion_matrix(y_test, predictions)}\n",
        "\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX_vxnx16b8p"
      },
      "source": [
        "In all this tutorial, we have tried to predict sleep stages from precomputed features (spectral or other features). \n",
        "\n",
        "Scikit provides methods to assess to importance of each feature for the prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAfKM6ys7wPb"
      },
      "source": [
        "# load spectrogram dataset and shuffle train data\n",
        "x_train, y_train = x_train_feat, y_train_feat\n",
        "list_features = features_name\n",
        "\n",
        "# let's take an already trained classifier\n",
        "clf = stacking_classifier\n",
        "\n",
        "# permutation importance > feature importance\n",
        "print('permutations...')\n",
        "from sklearn.inspection import permutation_importance\n",
        "result = permutation_importance(clf, x_train, y_train, n_repeats=10, random_state=0)\n",
        "\n",
        "# sort by importance\n",
        "sorted_idx = result.importances_mean.argsort()\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(25, 10))\n",
        "ax.boxplot(result.importances[sorted_idx].T,\n",
        "           vert=False, labels=[list_features[i] for i in sorted_idx])\n",
        "ax.set_title(\"Permutation Importances (train set)\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjnFmonvZL0x"
      },
      "source": [
        "You've reached the end of this second tutorial.\n",
        "\n",
        "Let's go to the last part about deep learning methods.\n",
        "Open the **Tutorial_Sleep_Staging_C** tutorial"
      ]
    }
  ]
}