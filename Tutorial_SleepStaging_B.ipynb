{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tutorial_SleepStaging_B.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOeecMcdZnUYNBLqnj5m9jc"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"25mYtkZbNgnq"},"source":["Launch the following blocks to connect to your drive and go into the tutorial folder"]},{"cell_type":"code","metadata":{"id":"XpSZkaqFDrRN","executionInfo":{"status":"ok","timestamp":1603055014557,"user_tz":-120,"elapsed":728,"user":{"displayName":"Karim el Kanbi","photoUrl":"","userId":"15502708993880309867"}},"outputId":"601205e3-1e01-41ad-dcb3-05cfd00ed597","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pokgRnDVDxzZ","executionInfo":{"status":"ok","timestamp":1603055014889,"user_tz":-120,"elapsed":1050,"user":{"displayName":"Karim el Kanbi","photoUrl":"","userId":"15502708993880309867"}},"outputId":"4aaef4a7-2431-4151-d06b-709049469d40","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["%cd /content/gdrive/My\\ Drive/TD_Dreem_MasterBin/Dreem_Master_Bin\n","! ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/TD_Dreem_MasterBin/Dreem_Master_Bin\n","data\t\t  README.md\t\tTutorial_Sleep_Staging_A.ipynb\n","dreem_master_bin  README.rst\t\tTutorial_SleepStaging_B.ipynb\n","poetry.lock\t  TD_SleepStaging_B.py\n","pyproject.toml\t  tests\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Br682vIyDkCy"},"source":["This tutorial is about machine learning methods for sleep stage classification.\n"]},{"cell_type":"code","metadata":{"id":"ZONWWYI-hKl6","executionInfo":{"status":"ok","timestamp":1603055015187,"user_tz":-120,"elapsed":1340,"user":{"displayName":"Karim el Kanbi","photoUrl":"","userId":"15502708993880309867"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","\n","from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, confusion_matrix\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","from dreem_master_bin.hypnogram import plot_hypnogram, stage_colors"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GnHoNfP4hLUl"},"source":["To save you some time, train and test datasets are and are available in the data folder. It consists of preprocessed data, not raw record. You have two types of datasets:\n","\n","- Spectral dataset = data containing spectral power (spectrogram matrix): train and test\n","- Features dataset = data containing precomputed features: train and test"]},{"cell_type":"code","metadata":{"id":"KfzUJqPPboAi","executionInfo":{"status":"ok","timestamp":1603055015432,"user_tz":-120,"elapsed":1580,"user":{"displayName":"Karim el Kanbi","photoUrl":"","userId":"15502708993880309867"}}},"source":["from dreem_master_bin.load_data import load_spectral_datasets, load_feature_datasets\n","\n","# load spectrogram dataset and shuffle train data\n","x_train_spect, y_train_spect, x_test_spect, y_test_spect = load_spectral_datasets()\n","# shuffle train dataset\n","p = np.random.permutation(len(y_train_spect))\n","x_train_spect, y_train_spect = x_train_spect[p], y_train_spect[p]\n","\n","\n","# load precomputed features dataset and shuffle train data\n","x_train_feat, y_train_feat, x_test_feat, y_test_feat = load_feature_datasets()\n","features_name = ['index_window', 'delta', 'delta_r', 'theta', 'theta_r',\n","       'lowfreq', 'lowfreq_r', 'alpha', 'alpha_r', 'sigma', 'sigma_r', 'beta',\n","       'beta_r', 'kcomp', 'kcomp_r', 'SC', 'SEF90', 'SEF95', 'Nb spindles',\n","       'spindles magnitude', 'spindles duration', 'Nb slow waves',\n","       'slow waves magnitude', 'slow waves duration', 'AccelerometerVar',\n","       'little movement', 'strong movement']\n","# shuffle train dataset\n","p = np.random.permutation(len(y_train_feat))\n","x_train_feat, y_train_feat = x_train_feat[p], y_train_feat[p]"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UMXTLgSVb-Vk"},"source":["We have just loaded the spectral data:\n","\n","- x_train_spect, x_test_spect: spectral data to predict sleep stages\n","It is an array of shape n_samples x n_features\n","\n","    - n_samples = number of sleep epochs\n","    - n_features = number of features for each of these epochs. The features are: [index_window, power_frequency_1Hz, power_frequency_2Hz, ..., power_frequency_18Hz], where index window to the position of the sample in its sleep record.\n","- y_train_spect, y_test_spect: labels (sleep stages)\n","\n","Then, we have loaded the other dataset:\n","\n","- x_train_spect, x_test_spect: shape n_samples x n_features\n","    - n_features = the features are ['index_window', 'delta', 'delta_r', 'theta', 'theta_r', 'lowfreq', 'lowfreq_r', 'alpha', 'alpha_r', 'sigma', 'sigma_r', 'beta', 'beta_r', 'kcomp', 'kcomp_r', 'SC', 'SEF90', 'SEF95', 'Nb spindles', 'spindles magnitude', 'spindles duration', 'Nb slow waves', 'slow waves magnitude', 'slow waves duration', 'AccelerometerVar','little movement', 'strong movement']\n","\n","- y_train_spect, y_test_spect: labels (sleep stages)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"68gD5UbGEDod"},"source":["Let's start with the spectral dataset !"]},{"cell_type":"code","metadata":{"id":"uZcvEkUvDjWX","executionInfo":{"status":"ok","timestamp":1603055015433,"user_tz":-120,"elapsed":1576,"user":{"displayName":"Karim el Kanbi","photoUrl":"","userId":"15502708993880309867"}}},"source":["x_train, y_train = x_train_spect, y_train_spect\n","x_test, y_test = x_test_spect, y_test_spect"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jv-Rft5PEcHk"},"source":["1 - Dimension reduction + (linear) classifier\n","\n","- Choose an algorithm for dimension reduction (e.g PCA)\n","- Choose a (linear) classifier (e.g SVM classifier)\n","\n","\n","You can go to the online documentation of the scikit-library to find similar functions, with the keywords: \n","- multi class classifier\n","- dimension reduction\n","- decomposition\n"]},{"cell_type":"code","metadata":{"id":"Ekji3UiPEO5_","executionInfo":{"status":"ok","timestamp":1603055045690,"user_tz":-120,"elapsed":31828,"user":{"displayName":"Karim el Kanbi","photoUrl":"","userId":"15502708993880309867"}},"outputId":"817dd637-1129-4620-dd9d-ddf2747d1dfa","colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from sklearn.decomposition import PCA\n","from sklearn.svm import SVC\n","\n","# scale input data and reduce dimension\n","pca = make_pipeline(StandardScaler(),\n","                    PCA(n_components=5, random_state=10))\n","pca.fit(x_train, y_train)\n","\n","# linear classifier\n","classifier = SVC(kernel='linear')\n","# training: fit the model to the data\n","classifier.fit(pca.transform(x_train), y_train)\n","\n","# test it\n","predictions = classifier.predict(pca.transform(x_test))\n","scores = {'balanced_accuracy': balanced_accuracy_score(y_test, predictions),\n","            'cohen_kappa': cohen_kappa_score(y_test, predictions),\n","            'confusion_matrix': confusion_matrix(y_test, predictions)}\n","\n","scores"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'balanced_accuracy': 0.4599662021569129,\n"," 'cohen_kappa': 0.4583312698272156,\n"," 'confusion_matrix': array([[ 246,    0,  275,   63,  198],\n","        [   2,    0,   65,    0,   43],\n","        [  41,    0, 2361,  272,  426],\n","        [  30,    0,  532, 1190,   32],\n","        [  66,    0,  920,   52, 1303]])}"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"7---cUpLE-lN"},"source":["2 - Ensemble learning\n","https://scikit-learn.org/stable/modules/ensemble.html\n","\n","Here we are going to use the Random Forest method, try to use other ensemble learning functions of the scikit-learn library.\n","Also we are going to work with preprocessed features.\n","\n","Go to the online documentation of these functions to set the parameters\n","\n"]},{"cell_type":"code","metadata":{"id":"Fp7B5w_GHhYH","executionInfo":{"status":"ok","timestamp":1603055298445,"user_tz":-120,"elapsed":7602,"user":{"displayName":"Karim el Kanbi","photoUrl":"","userId":"15502708993880309867"}},"outputId":"414be1f0-d7dd-4da6-9b9e-24bba8e5df4b","colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["# load spectrogram dataset and shuffle train data\n","x_train, y_train = x_train_feat, y_train_feat\n","x_test, y_test = x_test_feat, y_test_feat\n","\n","# select a classifier and train it\n","from sklearn.ensemble import RandomForestClassifier\n","\n","clf_rf = make_pipeline(StandardScaler(),\n","                       RandomForestClassifier(max_depth=10, random_state=42))\n","print('training...')\n","clf_rf.fit(x_train, y_train)\n","\n","# test it\n","predictions = clf_rf.predict(x_test)\n","scores = {'balanced_accuracy': balanced_accuracy_score(y_test, predictions),\n","            'cohen_kappa_score': cohen_kappa_score(y_test, predictions),\n","            'confusion_matrix': confusion_matrix(y_test, predictions)}\n","\n","scores"],"execution_count":9,"outputs":[{"output_type":"stream","text":["training...\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'balanced_accuracy': 0.5388792251015921,\n"," 'cohen_kappa_score': 0.5239186907044804,\n"," 'confusion_matrix': array([[ 550,    0,  132,   25,   75],\n","        [  10,    0,   36,    4,   60],\n","        [  52,    0, 2396,  330,  322],\n","        [  22,    0,  575, 1181,    6],\n","        [  90,    0,  902,   47, 1302]])}"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"H0nHioKyTpdz"},"source":["3 - Stack multiple estimators\n","\n","It is possible to combine multiple machine learning algorithms to improve performance.\n","\n","> Use the StackingClassifier to stack estimators with a final classifier\n"]},{"cell_type":"code","metadata":{"id":"sxRGV5fRTvx5","executionInfo":{"status":"ok","timestamp":1603055352034,"user_tz":-120,"elapsed":43800,"user":{"displayName":"Karim el Kanbi","photoUrl":"","userId":"15502708993880309867"}},"outputId":"ece11109-020a-4964-a2cc-5fa524139af8","colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["# select a classifier and train it\n","from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","rf_pipeline = make_pipeline(StandardScaler(),\n","                            RandomForestClassifier(n_estimators=10, random_state=42))\n","gradient_pipeline = make_pipeline(StandardScaler(),\n","                                  HistGradientBoostingClassifier(learning_rate=0.01, random_state=30))\n","estimators = [('Random Forest', rf_pipeline),\n","                  ('Gradient Boosting', gradient_pipeline)]\n","stacking_classifier = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=200))\n","\n","print('training...')\n","stacking_classifier.fit(x_train, y_train)\n","\n","# test it\n","predictions = stacking_classifier.predict(x_test)\n","scores = {'balanced_accuracy': balanced_accuracy_score(y_test, predictions),\n","          'cohen_kappa_score': cohen_kappa_score(y_test, predictions),\n","          'confusion_matrix': confusion_matrix(y_test, predictions)}\n","\n","scores"],"execution_count":10,"outputs":[{"output_type":"stream","text":["training...\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'balanced_accuracy': 0.5459091123132196,\n"," 'cohen_kappa_score': 0.5320457187229523,\n"," 'confusion_matrix': array([[ 565,    0,  121,   14,   82],\n","        [  15,    0,   43,    1,   51],\n","        [  54,    0, 2349,  335,  362],\n","        [  20,    0,  564, 1187,   13],\n","        [  98,    0,  848,   28, 1367]])}"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"yjnFmonvZL0x"},"source":["Let's go to the last part about deep learning methods.\n","Open the **Tutorial_Sleep_Staging_C[link text](https://)** tutorial"]}]}